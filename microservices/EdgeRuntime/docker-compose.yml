# EdgeRuntime - Unified Docker Compose
# Combines CDC data sync (Kafka Connect) + FreeRADIUS + ClickHouse (accounting analytics)
#
# Architecture:
#   Cloud Kafka ──► Kafka Connect (JDBC Sink) ──► PostgreSQL ◄── FreeRADIUS (auth)
#   FreeRADIUS ──► linelog (JSON) ──► Fluent Bit ──► ClickHouse (sole accounting destination)
#   FreeRADIUS ◄──► Redis (auth cache, session tracking, rate limiting)

services:
  # ============================================================================
  # PostgreSQL - Primary edge database
  # Stores CDC-synced users/NAS from cloud + FreeRADIUS postauth logs
  # ============================================================================
  postgres:
    image: postgres:18.1
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_postgres
    command: >
      postgres
      -c wal_level=logical
      -c max_connections=200
      -c shared_buffers=256MB
      -c work_mem=8MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=128MB
      -c checkpoint_completion_target=0.9
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-edge_db}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme_in_production}
    ports:
      - "${POSTGRES_PORT:-5434}:5432"
    volumes:
      - ./init/postgres:/docker-entrypoint-initdb.d
      - postgres_data:/var/lib/postgresql
    networks:
      - edge-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-edge_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ============================================================================
  # Redis - Session cache, auth cache, rate limiting
  # DB 0: General / DB 1: Sessions / DB 2: Auth cache / DB 3: Rate limiting
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_redis
    command: >
      redis-server
      --maxmemory ${REDIS_MAX_MEMORY:-512mb}
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --save 60 1000
      --tcp-backlog 511
      --timeout 300
    ports:
      - "${REDIS_PORT:-6380}:6379"
    volumes:
      - redis_data:/data
    networks:
      - edge-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # Kafka Connect (Debezium JDBC Sink) - CDC sync from cloud
  # Consumes change events from cloud Kafka and writes to local PostgreSQL
  # ============================================================================
  connect:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_connect
    platform: linux/amd64
    extra_hosts:
      - "kafka.open-radius.org:${KAFKA_HOST_IP:-157.230.113.249}"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-157.230.113.249:9094}
      GROUP_ID: ${CONNECTOR_GROUP_ID:-2}
      CONFIG_STORAGE_TOPIC: connect_configs_${COMPOSE_PROJECT_NAME:-edge}
      OFFSET_STORAGE_TOPIC: connect_offsets_${COMPOSE_PROJECT_NAME:-edge}
      STATUS_STORAGE_TOPIC: connect_status_${COMPOSE_PROJECT_NAME:-edge}
      REST_ADVERTISED_HOST_NAME: ${COMPOSE_PROJECT_NAME:-edge}_connect
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "true"
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: "10000"
      CONNECT_OFFSET_FLUSH_TIMEOUT_MS: "5000"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      KAFKA_HEAP_OPTS: "-Xms512M -Xmx2G"
      # SASL/SCRAM authentication to cloud Redpanda broker
      CONNECT_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_SASL_MECHANISM: SCRAM-SHA-256
      CONNECT_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_SASL_USERNAME:-admin}\" password=\"${KAFKA_SASL_PASSWORD:-changeme_in_production}\";"
      # SASL for consumer (reading from cloud topics)
      CONNECT_CONSUMER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_CONSUMER_SASL_MECHANISM: SCRAM-SHA-256
      CONNECT_CONSUMER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_SASL_USERNAME:-admin}\" password=\"${KAFKA_SASL_PASSWORD:-changeme_in_production}\";"
      # SASL for producer (writing consumer offsets back)
      CONNECT_PRODUCER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONNECT_PRODUCER_SASL_MECHANISM: SCRAM-SHA-256
      CONNECT_PRODUCER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_SASL_USERNAME:-admin}\" password=\"${KAFKA_SASL_PASSWORD:-changeme_in_production}\";"
    ports:
      - "${CONNECT_PORT:-8084}:8083"
    networks:
      - edge-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ============================================================================
  # ClickHouse - Columnar analytics engine for RADIUS accounting
  # High-performance storage for session data, traffic analytics, reporting
  # ============================================================================
  clickhouse:
    image: clickhouse/clickhouse-server:24.8-alpine
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_clickhouse
    environment:
      CLICKHOUSE_DB: ${CLICKHOUSE_DB:-radius_analytics}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-radius}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-changeme_in_production}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ports:
      - "${CLICKHOUSE_HTTP_PORT:-8123}:8123"
      - "${CLICKHOUSE_NATIVE_PORT:-9000}:9000"
    volumes:
      - ./init/clickhouse:/docker-entrypoint-initdb.d
      - ./config/clickhouse/config.xml:/etc/clickhouse-server/config.d/custom.xml:ro
      - ./config/clickhouse/users.xml:/etc/clickhouse-server/users.d/custom.xml:ro
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    networks:
      - edge-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "clickhouse-client", "--host", "localhost", "--query", "SELECT 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 512M
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ============================================================================
  # Fluent Bit - Log processor & accounting pipeline
  # Tails FreeRADIUS JSON accounting logs and streams to ClickHouse via HTTP
  # ============================================================================
  fluent-bit:
    image: fluent/fluent-bit:3.2
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_fluent_bit
    environment:
      LOG_LEVEL: ${LOG_LEVEL:-info}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-radius}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-changeme_in_production}
      CLICKHOUSE_DB: ${CLICKHOUSE_DB:-radius_analytics}
      EDGE_SITE_ID: ${EDGE_SITE_ID:-}
    volumes:
      - ./config/fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./config/fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - ./config/fluent-bit/sanitize.lua:/fluent-bit/etc/sanitize.lua:ro
      - radius_logs:/var/log/radius:ro
      - fluent_bit_data:/fluent-bit/data
    depends_on:
      clickhouse:
        condition: service_healthy
    ports:
      - "${FLUENT_BIT_METRICS_PORT:-2020}:2020"
    networks:
      - edge-network
    restart: unless-stopped
    healthcheck:
      disable: true
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================================
  # FreeRADIUS 3.2 - RADIUS authentication and accounting server
  # Auth: reads users/NAS from local PostgreSQL (CDC synced) + Redis caching
  # Acct: ClickHouse (linelog JSON → Fluent Bit → ClickHouse, insert-only)
  #       + Redis (real-time session state for online users)
  # ============================================================================
  freeradius:
    image: freeradius/freeradius-server:latest
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_freeradius
    ports:
      - "${RADIUS_AUTH_PORT:-1812}:1812/udp"
      - "${RADIUS_ACCT_PORT:-1813}:1813/udp"
      - "${RADIUS_STATUS_PORT:-18120}:18120"
    volumes:
      - ./config/freeradius/radiusd.conf:/etc/freeradius/radiusd.conf:ro
      - ./config/freeradius/clients.conf:/etc/freeradius/clients.conf:ro
      - ./config/freeradius/mods-available/sql:/etc/freeradius/mods-available/sql:ro
      - ./config/freeradius/mods-enabled/sql:/etc/freeradius/mods-enabled/sql:ro
      - ./config/freeradius/mods-config/sql/main/postgresql/queries.conf:/etc/freeradius/mods-config/sql/main/postgresql/queries.conf:ro
      - ./config/freeradius/mods-available/redis:/etc/freeradius/mods-available/redis:ro
      - ./config/freeradius/mods-enabled/redis:/etc/freeradius/mods-enabled/redis:ro
      - ./config/freeradius/mods-available/linelog_accounting:/etc/freeradius/mods-available/linelog_accounting:ro
      - ./config/freeradius/mods-enabled/linelog_accounting:/etc/freeradius/mods-enabled/linelog_accounting:ro
      - ./config/freeradius/mods-available/perl_session_tracker:/etc/freeradius/mods-available/perl_session_tracker:ro
      - ./config/freeradius/mods-enabled/perl_session_tracker:/etc/freeradius/mods-enabled/perl_session_tracker:ro
      - ./config/freeradius/scripts/session_tracker.pl:/etc/freeradius/scripts/session_tracker.pl:ro
      - ./config/freeradius/sites-available/default:/etc/freeradius/sites-available/default:ro
      - ./config/freeradius/sites-enabled/default:/etc/freeradius/sites-enabled/default:ro
      - ./config/freeradius/dictionary:/etc/freeradius/dictionary:ro
      - radius_logs:/var/log/radius
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      TZ: ${TZ:-UTC}
    networks:
      - edge-network
    restart: unless-stopped
    command: ["${RADIUS_CMD:--X}"]
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ============================================================================
  # Metabase - BI & Analytics Dashboard for ClickHouse data
  # Browse accounting data, build dashboards, debug queries
  # Default login: set up on first visit at http://localhost:3300
  # ============================================================================
  metabase:
    image: metabase/metabase:latest
    container_name: ${COMPOSE_PROJECT_NAME:-edge}_metabase
    ports:
      - "${METABASE_PORT:-3300}:3000"
    environment:
      MB_DB_TYPE: h2
      MB_DB_FILE: /metabase-data/metabase.db
      JAVA_TOOL_OPTIONS: "-Xmx512m"
    volumes:
      - metabase_data:/metabase-data
      - ./plugins:/plugins
    depends_on:
      clickhouse:
        condition: service_healthy
    networks:
      - edge-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  edge-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  clickhouse_data:
    driver: local
  clickhouse_logs:
    driver: local
  radius_logs:
    driver: local
  fluent_bit_data:
    driver: local
  metabase_data:
    driver: local
